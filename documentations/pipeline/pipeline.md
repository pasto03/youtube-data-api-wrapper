> **Note**: This documentation was generated by AI and may contain inaccuracies. Please verify information and refer to the source code for authoritative details.

# Pipeline Component

## Overview

The **Pipeline** component chains multiple **Foreman** units into automated, multi-step workflows. It automatically extracts IDs from one step's output and passes them as input to the next step, creating powerful data processing pipelines.

## Purpose

Pipelines enable:

- **Automated Workflows** — Chain multiple API calls automatically
- **Data Transformation** — Transform data through multiple steps
- **Complex Queries** — Build sophisticated data retrieval patterns
- **Quota Management** — Estimate costs before execution
- **Execution Tracking** — Get detailed reports on pipeline execution

## Key Features

1. **Linear Pipelines** — Sequential execution of multiple steps
2. **Branched Pipelines** — Tree-based execution with multiple paths
3. **Automatic ID Extraction** — Automatically extracts IDs from one step to feed the next
4. **Connection Validation** — Validates that pipeline blocks can be connected
5. **Quota Estimation** — Estimate API quota costs before execution
6. **Execution Reports** — Detailed metrics on execution time, quota usage, and data flow
7. **String Notation** — Build pipelines using intuitive string syntax

## Architecture

Pipelines orchestrate multiple Foremen:

```
Initial Input → Foreman₁ → Extract IDs → Foreman₂ → Extract IDs → ... → Final Output
```

### Pipeline Types

#### 1. Linear Pipeline (`Pipeline`)

- **Structure**: Sequential, one step after another
- **Use Case**: Straightforward data processing workflows
- **Example**: Search → Videos → Comments

#### 2. Branched Pipeline (`BranchedPipeline`)

- **Structure**: Tree-based, multiple execution paths
- **Use Case**: Complex workflows with branching logic
- **Example**: Search → [Channels → Playlists, Videos → Comments]

## Connection Rules

Pipelines validate that blocks can be connected. Valid connections:

- `search` → `videos`, `channels`, `playlists`, `playlist_items`, `search`
- `channels` → `playlists`
- `playlists` → `playlist_items`
- `playlist_items` → `videos`
- `videos` → `comments`, `captions`

Invalid connections will raise errors during pipeline construction.

## Pipeline Construction

### Method 1: Object Notation

```python
from yt_pipeline.pipeline import Pipeline, PipelineBlock, PipelineStacks
from yt_pipeline.foreman import SearchForeman, VideosForeman
from yt_pipeline.retriever import RetrieverSettings, PipeSettings, SearchParamProps, SearchTypeCheckboxProps

stacks = PipelineStacks(
    initial_input=[SearchParamProps(q="python tutorial")],
    blocks=[
        PipelineBlock(
            foreman=SearchForeman(types=SearchTypeCheckboxProps(video=True)),
            pipe_settings=PipeSettings(max_page=1),
            retriever_settings=RetrieverSettings(multithread=True),
            max_workers=8
        ),
        PipelineBlock(
            foreman=VideosForeman(),
            retriever_settings=RetrieverSettings(multithread=True)
        )
    ]
)

pipeline = Pipeline(stacks=stacks, developerKey=devKey)
```

### Method 2: String Notation

```python
from yt_pipeline.pipeline import Pipeline, PipelineStacks, PipelineBlocksConstructor
from yt_pipeline.retriever import RetrieverSettings, PipeSettings, SearchParamProps

constructor = PipelineBlocksConstructor(
    retriever_settings=RetrieverSettings(multithread=True),
    pipe_settings=PipeSettings(max_page=1)
)

pipeline_blocks = constructor.construct(
    "search(video)<save_output max_page(1)> -> videos<save_output>"
)

stacks = PipelineStacks(
    initial_input=[SearchParamProps(q="python tutorial")],
    blocks=pipeline_blocks
)

pipeline = Pipeline(stacks=stacks, developerKey=devKey)
```

## Execution

### Basic Execution

```python
result = pipeline.invoke()
```

### With Quota Estimation

```python
from yt_pipeline.pipeline import PipelineEstimator

# Estimate quota before execution
estimator = PipelineEstimator(pipeline)
report = estimator.estimate()
report.display(metrics="all")

# Execute if quota is acceptable
result = pipeline.invoke()
```

## Output Structure

### PipelineDeliverable

Linear pipelines return a `PipelineDeliverable`:

```python
result.products  # List of PipelineProduct objects
result.report    # PipelineExecutionReport
```

Each product contains:

- `title`: Foreman name
- `shipper`: Shipper object with data

### BranchedPipelineDeliverable

Branched pipelines return a `BranchedPipelineDeliverable`:

```python
result.head_product  # PipelineProductNode (tree structure)
result.report        # BranchedPipelineExecutionReport
```

## Settings & Configuration

### PipelineBlock

Each block in a pipeline can have:

- `foreman`: Foreman instance
- `pipe_settings`: PipeSettings for pagination
- `retriever_settings`: RetrieverSettings for execution
- `save_output`: Whether to save this block's output
- `backup_shipper`: Whether to backup shipper data
- `max_workers`: Number of concurrent threads
- `debug`: Enable debug logging

## Quota Estimation

Estimate quota costs before execution:

```python
from yt_pipeline.pipeline import PipelineEstimator

estimator = PipelineEstimator(pipeline)
report = estimator.estimate()

# Display all metrics
report.display(metrics="all")

# Access specific metrics
print(report.overall_cost)      # Total quota cost
print(report.estimated_time)    # Estimated execution time
```

## Execution Reports

Get detailed execution metrics:

```python
result = pipeline.invoke()

# Display report
result.report.display(metrics="all")

# Access metrics
print(result.report.overall_cost)
print(result.report.execution_time)
print(result.report.stages)  # List of stage reports
```

## Error Handling

Pipelines handle errors gracefully:

- **Validation Errors**: Raised during construction if blocks can't be connected
- **Execution Errors**: Stored in `pipeline_errors` and returned in deliverable
- **Early Termination**: Pipeline stops if a block returns no items

## Best Practices

1. **Estimate First** — Always estimate quota before running large pipelines
2. **Use String Notation** — For rapid prototyping, switch to object notation for production
3. **Save Outputs** — Use `save_output=True` to capture intermediate results
4. **Limit Pagination** — Use `max_page` to control pagination for large result sets
5. **Enable Multithreading** — Use `multithread=True` for better performance

## Related Documentation

- **[Linear Pipeline](./linear-pipeline.md)** — Detailed guide to sequential pipelines
- **[Branched Pipeline](./branched-pipeline.md)** — Tree-based pipeline guide
- **[Pipeline Estimator](./pipeline-estimator.md)** — Quota estimation guide
- **[Pipeline Constructor](./pipeline-constructor.md)** — String notation guide
- **[Use Cases](./use-cases.md)** — Practical pipeline examples

## Next Steps

- Read about [Linear Pipelines](./linear-pipeline.md) for sequential workflows
- Learn about [Branched Pipelines](./branched-pipeline.md) for complex workflows
- Explore [Pipeline Use Cases](./use-cases.md) for practical examples
